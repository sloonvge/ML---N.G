{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import re\n",
    "import nltk, nltk.stem.porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preprocess sample eamil\n",
    "def processEmail(text):\n",
    "    \n",
    "    word_indices = []\n",
    "    #lower case\n",
    "    text = text.lower()\n",
    "    #strip all html\n",
    "    text = re.sub('<[^<>]+>', ' ', text)\n",
    "    #0-9 to number\n",
    "    text = re.sub('[0-9]+', 'number', text)\n",
    "    #http:// to httpaddr\n",
    "    text = re.sub('(http|https)://[^\\s]*', 'httpaddr', text)\n",
    "    # handle addresses\n",
    "    text = re.sub('[^\\s]+@[^\\s]+', 'emailaddr', text)\n",
    "    # handle sign\n",
    "    text = re.sub('[$]+', 'dollar', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def email2TokenList(raw_text):\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()#提取词干\n",
    "    email = processEmail(raw_text)\n",
    "    tokens = re.split('[ \\@\\$\\/\\#\\.\\-\\:\\&\\*\\+\\=\\[\\]\\?\\!\\(\\)\\{\\}\\,\\'\\\"\\>\\_\\<\\;\\%]', email)\n",
    "    tokenlist = []\n",
    "    for token in tokens: \n",
    "        #Remove any non alphanumeric characters\n",
    "        token = re.sub('[^a-zA-Z0-9]', '', token)\n",
    "        #Use the Porter stemmer to stem the word\n",
    "        stemmed = stemmer.stem(token)\n",
    "        #Throw out empty tokens\n",
    "        if not len(token): continue  \n",
    "        #Store a list of all unique stemmed words\n",
    "        tokenlist.append(stemmed)\n",
    "    return tokenlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getVocabDict(reverse=False):\n",
    "    vocab_dict = {}\n",
    "    with open(\"vocab.txt\") as f:\n",
    "        for line in f:\n",
    "            (val, key) = line.split()\n",
    "            if not reverse:\n",
    "                vocab_dict[key] = int(val)\n",
    "            else:\n",
    "                vocab_dict[int(val)] = key     \n",
    "    return vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def email2VocabIndices(raw_text, vocab_dict):\n",
    "    tokenlist = email2TokenList(raw_text)\n",
    "    index_list = [ vocab_dict[token] for token in tokenlist if token in vocab_dict ]\n",
    "    return index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wordIndices(file):\n",
    "    with open(file, 'r') as f:\n",
    "        word_indices = []\n",
    "        vocab_list = getVocabDict()\n",
    "        for i in f:\n",
    "            a=email2VocabIndices(i, vocab_list)\n",
    "            word_indices.extend(a)\n",
    "    return word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2.2 Extracting Features from Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def emailFeatures(indices, vocab_dict):\n",
    "    word_vec = np.zeros((len(vocab_dict), 1))\n",
    "    for index in indices:\n",
    "        word_vec[index, 0] = 1 \n",
    "    return word_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1899, 1) (128,)\n"
     ]
    }
   ],
   "source": [
    "word_indices = wordIndices('emailSample2.txt')\n",
    "vocab_list = getVocabDict()\n",
    "sample1_fea = emailFeatures(word_indices, vocab_list)\n",
    "print(sample1_fea.shape, sample1_fea[np.where(sample1_fea==1)].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2.3 Training SVM for Spam Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sio.loadmat('spamTrain.mat')\n",
    "data_test = sio.loadmat('spamTest.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data['X']\n",
    "y = data['y']\n",
    "X_test = data_test['Xtest']\n",
    "y_test = data_test['ytest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_svm = svm.SVC(C=1, kernel='linear')\n",
    "email_svm.fit(X, y.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.99975\n",
      "Test accuracy: 0.978\n"
     ]
    }
   ],
   "source": [
    "train_pred = email_svm.predict(X).reshape(len(y), 1)\n",
    "train_acc = (train_pred==y).mean()\n",
    "print('Train accuracy:', train_acc)\n",
    "test_pred = email_svm.predict(X_test).reshape(len(y_test), 1)\n",
    "test_acc = (test_pred==y_test).mean()\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2.4 Top Predictors for Spam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 15 most important words to classify a spam e-mail are:\n",
      "['otherwis', 'flag', 'why', 'numberanumb', 'remot', 'visa', 'clearli', 'board', 'gt', 'seminar', 'technolog', 'institut', 'dollarac', 'titl', 'base']\n",
      "The 15 least important words to classify a spam e-mail are:\n",
      "['success', 'useless', 'that', 'http', 'et', 'urgent', 'instant', 'datapow', 'spam', 'steve', 'addit', 'kid', 'round', 'wrong', 'studi']\n"
     ]
    }
   ],
   "source": [
    "vocab_dict_flipped = getVocabDict(reverse=True)\n",
    "\n",
    "#Sort indicies from most important to least-important (high to low weight)\n",
    "sorted_indices = np.argsort( -email_svm.coef_, axis=1 )\n",
    "print(\"The 15 most important words to classify a spam e-mail are:\")\n",
    "print([ vocab_dict_flipped[x] for x in sorted_indices[0,:15] ])\n",
    "print(\"The 15 least important words to classify a spam e-mail are:\")\n",
    "print([ vocab_dict_flipped[x] for x in sorted_indices[0,-15:] ])\n",
    "\n",
    "\n",
    "# Most common word (mostly to debug):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=uint8)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_svm.predict(sample1_fea.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
